# LinearRegression
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data = pd.read_csv("./Datasets/diabetes.csv")

# Select features and target
X = data[['BMI']]  # Independent variable
y = data['Outcome']  # Dependent variable (target)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Get the model coefficients
# y = β0 + β1⋅x
intercept = model.intercept_  # Intercept (β₀)
coefficient = model.coef_[0]  # Coefficient (β₁)

# Predict on the test data
y_pred = model.predict(X_test)

# Calculate residual sum of squares (RSS)
rss = ((y_test - y_pred) ** 2).sum()

# Calculate R-squared (coefficient of determination)
r2 = r2_score(y_test, y_pred)

# Calculate Mean Squared Error
mse = mean_squared_error(y_test, y_pred)

# Output the results
print(f"Intercept (β₀): {intercept}")
print(f"Coefficient (β₁): {coefficient}")
print(f"Residual Sum of Squares (RSS): {rss}")
print(f"Coefficient of Determination (R²): {r2}")
print("Mean Squared Error:", mse)

# Plotting the regression line
# plt.figure(figsize=(8, 6))
# sns.scatterplot(x=X_test['BMI'], y=y_test, color='blue', label='Actual Data')
# plt.plot(X_test, y_pred, color='red', label='Regression Line', linewidth=2)
# plt.xlabel('BMI')
# plt.ylabel('Outcome')
# plt.title('Linear Regression: BMI vs. Outcome')
# plt.legend()
# plt.show()

sns.regplot(x='BMI', y='Outcome', data=data)